{"timestamp": 1697656091.939186, "stored_source_code": "# declare a list tasks whose products you want to use as inputs\nupstream = None\n# AUTOGENERATED! DO NOT EDIT! File to edit: datadownload.ipynb.\n__all__ = ['model_dict', 'transmission_dict', 'fuel_dict', 'extract_metadata', 'extract_raw_data', 'merge_top_two_rows',\n           'rename_columns', 'clean_content', 'init_duckdb', 'create_duckdb_table']\nfrom pathlib import Path\nimport requests\nimport csv\nfrom io import StringIO\nimport pandas as pd\nimport json\nimport duckdb\ndef extract_metadata(metadata_url):\n    \"\"\"\n    Extracts a list of filenames and urls from Open Cananda metadata url.\n\n    Parameters\n    ----------\n    metadata_url : str\n        Fuel consumption ratings metadata url from Open Canada website.\n\n    Returns\n    -------\n    english_resources_df : pd.DataFrame\n        DataFrame of file names and urls for energy consumption ratings.\n    \"\"\"\n    try:      \n        metadata_resp = requests.get(metadata_url)\n    except requests.exceptions.RequestException as e:\n        # If request fails, return an error message and stop.\n        print(f'Error making url request: {e}')\n    \n    try:     \n        metadata_json = metadata_resp.json()\n    except json.JSONDecodeError:\n        # If parsing json fails, return an error message and stop.\n        print(f'Error: Response is not valid json')\n        \n    # Access list of downloadable resources\n    resources_df = pd.DataFrame(metadata_json['result']['resources'])\n\n    # Change language coding and extract English only resources\n    resources_df['language'] = resources_df['language'].apply(lambda item : item[0])\n    english_resources_df = resources_df[resources_df['language'] == 'en']\n    \n    return english_resources_df[['name', 'url']]\ndef extract_raw_data(url, file_name):\n    \"\"\"\n    Extract raw data from a URL\n\n    Parameters\n    ----------\n    url : str\n        URL to extract data from\n        \n    file_name : str or Path object\n        file name for raw data dump\n        \n    \"\"\"\n    \n    try:\n        # Request data from url\n        response = requests.get(url)\n        content_type = response.headers['content-type']\n        response_text = response.text\n        print(f'Response status: {response.status_code}\\nContent Type: {content_type}')\n\n        # Save request content to csv file\n        with open(file_name, mode='w', newline='') as csvfile:\n            csvfile.write(response_text)\n\n        print(f'csv file: {file_name} saved')\n        \n    # Catch errors    \n    except requests.exceptions.HTTPError as err_h:\n        print(f'HTTP error occured:{err_h}')\n    except requests.exceptions.ConnectionError as err_c:\n        print(f'Error connecting:{err_c}')\n    except requests.exceptions.Timeout as err_t:\n        print(f'Timeout Error:{err_t}')\n    except requests.exceptions.RequestException as err:\n        print(f'There was an unknown error:{err}')\ndef merge_top_two_rows(input_file, output_file):\n    # Open the input CSV file for reading\n    with open(input_file, mode='r', newline='') as csvfile:\n        reader = csv.reader(csvfile)\n        \n        # Read the first two rows from the input file\n        header_row = next(reader)\n        second_row = next(reader)\n        \n        # Merge the two rows into one header\n        merged_header = [f\"{header_row[i]} {second_row[i]}\" for i in range(len(header_row))]\n        \n        # Open the output CSV file for writing\n        with open(output_file, mode='w', newline='') as output_csvfile:\n            writer = csv.writer(output_csvfile)\n            \n            # Write the merged header to the output file\n            writer.writerow(merged_header)\n            \n            # Copy the rest of the rows from the input file to the output file\n            for row in reader:\n                writer.writerow(row)\ndef rename_columns(df):\n    \"\"\"\n    Removes unwanted DataFrame columns and rows, then cleans and renames column headers.\n\n    Parameters\n    ----------\n    df: DataFrame\n        DataFrame with columns to clean\n\n    Returns\n    -------\n    df: DataFrame\n        DataFrame with cleaned column headers\n\n    \"\"\"\n    # Drop empty columns and rows from the DataFrame\n    df.dropna(axis=1, how='all', inplace=True)\n    df.dropna(axis=0, thresh=5, inplace=True)\n\n    # Remove whitespace, replace spaces with _ and change to lower case\n    cleaned_cols = (df.columns.str.lower()\n                    .str.strip()\n                    .str.replace(' # = high output engine', '')\n                    .str.replace('*', '')\n                    .str.replace('  ', ' ')\n                    .str.replace(' ', '_')\n                    .str.replace('(', '')\n                    .str.replace(')', '')\n                    .str.replace('/', '_')\n                    .str.replace('fuel_consumption_', '')\n                    .str.replace('consumption_', '')\n                    .str.replace('_le_', '_l_')\n                    .str.replace('city_l_100_km', 'consumption_city_l_100_km')\n                    .str.replace('comb_l_100_km', 'consumption_comb_l_100_km')\n                    .str.replace('hwy_l_100_km', 'consumption_hwy_l_100_km')\n    )\n\n    col_mapper = dict(list(zip(df.columns, cleaned_cols))) # build a dictionary to map old column names to new\n    df.rename(columns=col_mapper, inplace=True)\n\n    return df  \ndef clean_content(df):\n    \"\"\"\n    Clean content of master_df columns\n\n    Parameters\n    ----------\n    df : DataFrame\n        Should be master_df containing all fuel rating data combined\n    \"\"\"\n    \n    # Set fuel type columns using fuel_dict\n    df['fuel_type'] = df['fuel_type'].map(fuel_dict)\n    df['fuel_type_1'] = df['fuel_type_1'].map(fuel_dict)\n    df['fuel_type_2'] = df['fuel_type_2'].map(fuel_dict)\n\n    # Set make, model and vehicle_class to lower case and remove \":\" characters\n    df['make'] = df['make'].str.lower().str.strip()\n    df['model'] = df['model'].str.lower().str.strip()\n    df['vehicle_class'] = df['vehicle_class'].str.lower().str.strip()\n    df['vehicle_class'] = df['vehicle_class'].str.replace(\":\", \"-\")\n\n    # Set make, model and vehicle_class to category columns\n    df['make'] = df['make'].astype('category')\n    df['model'] = df['model'].astype('category')\n    df['vehicle_class'] = df['vehicle_class'].astype('category')\n\n    # Split transmission column into transmission type and number of gears\n    df = df.join(df['transmission'].str.split(r\"(\\d+)\", expand=True)\n                          .drop(columns=[2])\n                          .rename(columns={0: 'transmission_type', 1: 'number_of_gears'})\n    )\n\n    df['transmission_type'] = df['transmission_type'].map(transmission_dict)\n    df.drop(columns='transmission', inplace=True)\n\n    df.reset_index()\n    df['id'] = df.index\n\n    return df\ndef init_duckdb(db_file_path, tables):\n    \"\"\"\n    Initialize a DuckDB data base and create tables for each DataFrame\n\n    Parameters\n    ----------\n    db_file_path : str\n        Path to the DuckDB database file\n    tables : list\n        Dictionary of table names and references to DataFrames for those tables \n    \"\"\"\n    db_connection = duckdb.connect(db_file_path)\n    for key, value in tables.items():\n        create_duckdb_table(db_connection, key, value)\ndef create_duckdb_table(db_connection, table_name, df):\n    \"\"\"\n    Create a table in DuckDB\n\n    Parameters\n    ----------\n    db_connection : duckdb.conect\n        Connection to DuckDB\n    table_name : str\n        Name of the table to be created\n    df : str\n        Nmae of the DataFrame to be used to create the table.\n    \"\"\"\n    db_connection.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n    db_connection.execute(f\"CREATE TABLE {table_name} AS SELECT * FROM {df}\")\nglobal model_dict\nglobal transmission_dict\nglobal fuel_dict\n\nmodel_dict = {\n    \"4wd/4X4\": \"Four-wheel drive\",\n    \"awd\": \"All-wheel drive\",\n    \"ffv\": \"Flexible-fuel vehicle\",\n    \"swb\": \"Short wheelbase\",\n    \"lwb\": \"Long wheelbase\",\n    \"ewb\": \"Extended wheelbase\",\n    \"cng\": \"Compressed natural gas\",\n    \"ngv\": \"Natural gas vehicle\",\n    \"#\": \"High output engine that \\\n            provides more power than the standard \\\n            engine of the same size\",\n}\n\ntransmission_dict = {\n    \"A\": \"automatic\",\n    \"AM\": \"automated manual\",\n    \"AS\": \"automatic with select Shift\",\n    \"AV\": \"continuously variable\",\n    \"M\": \"manual\",\n}\n\nfuel_dict = {\n    \"X\": \"regular gasoline\",\n    \"Z\": \"premium gasoline\",\n    \"D\": \"diesel\",\n    \"E\": \"ethanol (E85)\",\n    \"N\": \"natural gas\",\n    \"B\": \"electricity\",\n    \"B/X\": \"electricity & regular gasoline\",\n    \"B/Z\": \"electricity & premium gasoline\",\n    \"B/Z*\": \"electricity & premium gasoline\",\n    \"B/X*\": \"electricity & regular gasoline\",\n    \"B\": \"electricity\",\n}\nif __name__ == \"__main__\":\n    url = 'https://natural-resources.canada.ca/sites/nrcan/files/oee/files/csv/MY2023%20Fuel%20Consumption%20Ratings.csv'\n    metadata_url = 'https://open.canada.ca/data/api/action/package_show?id=98f1a129-f628-4ce4-b24d-6f16bf24dd64'\n    \n    # Build list of available resources\n    resources_df = extract_metadata(metadata_url)\n    \n    # Remove unwanted old resources\n    resources_df = resources_df[~resources_df['name'].str.contains('Original')]\n    \n    # Build filenames for desired resources and add to resources_df\n    file_names = (resources_df['name']\n         .str.replace(' ', '_')\n         .str.replace('(', 'v_')\n         .str.replace(')', '')\n         .str.lower()\n    )\n    resources_df.loc[:,'file_name'] = file_names\n    \n    # Build raw data file path\n    path = Path.cwd()\n    raw_path = path / 'pipeline' / 'data' / 'raw'\n    merged_header_path = path / 'pipeline' / 'data' / 'merged-headers'\n    \n    # Download and save raw data for each resource\n    for idx, row in resources_df.iterrows():\n        url = row.iloc[1]\n        file_name = row.iloc[2]\n        raw_file_name = raw_path / f'{file_name}.csv'\n        merged_header_file_name = merged_header_path / f'{file_name}.csv'\n        extract_raw_data(url, raw_file_name)\n        merge_top_two_rows(raw_file_name, merged_header_file_name)\n    \n    # Start a list of column headers and initiate a master_df\n    union_of_headers = set()\n    master_df = pd.DataFrame()\n    \n    # Build the master DataFrame\n    for idx, row in resources_df.iterrows():\n        # Open each csv file\n        url = row.iloc[1]\n        file_name = row.iloc[2]\n        merged_header_file_name = merged_header_path / f'{file_name}.csv'\n    \n        # Rename the columns\n        df = pd.read_csv(merged_header_file_name)\n        df = rename_columns(df)\n    \n        # Add vehicle type based on file_name\n        if 'hybrid' in file_name:\n            df['vehicle_type'] = 'hybrid'\n        elif 'electric' in file_name and 'hybrid' not in file_name:\n            df['vehicle_type'] = 'electric'\n        else:\n            df['vehicle_type'] = 'fuel-only'\n            \n        # Add any missing column headers to master DataFrame columns\n        union_of_headers = set.union(union_of_headers, set(df.columns))\n        missing_cols = set(master_df.columns) - union_of_headers\n        if len(missing_cols) > 0:\n            for col in missing_cols:\n                master_df[col] = pd.Series()\n            \n        # Concatenate current df with master_df\n        master_df = pd.concat([master_df, df], ignore_index=True)\n        \n    # Clean the master_df\n    master_df = clean_content(master_df)\n    \n    # Create separate fuel, electric, and hybrid DataFrames\n    electric_df = master_df.loc[master_df['vehicle_type'] == 'electric'].dropna(axis=1, how='all').reset_index()\n    hybrid_df = master_df.loc[master_df['vehicle_type'] == 'hybrid'].dropna(axis=1, how='all').reset_index()\n    fuel_df = master_df.loc[master_df['vehicle_type'] == 'fuel-only'].dropna(axis=1, how='all').reset_index()\n    \n    # Create dictionary to pass to init database\n    tables = {'all_vehicles' : 'master_df', 'electric' : 'electric_df', 'hybrid' : 'hybrid_df', 'fuel' : 'fuel_df'}\n    \n    # Create directory for DuckDB database \n    db_path = path / 'pipeline' / 'data' / 'database'\n    Path(db_path).mkdir(parents=True, exist_ok=True)\n    # Create file path for DuckDB database\n    db_file_path = str(db_path / 'car_data.duckdb')\n\n    # Create DuckDB database\n    init_duckdb(db_file_path, tables)\n\n    print(f'Data downloaded and saved in DuckDB database: {db_file_path}')", "params": {}}