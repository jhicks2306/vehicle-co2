{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e32f01a-32fd-41f0-b5d8-d2a83d7a6a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp datadownload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff1f2596-35b6-4e34-8c91-4179484884b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "import csv\n",
    "from io import StringIO\n",
    "from rich import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d648c9-d9ac-441a-83e3-a579a28b9fa3",
   "metadata": {},
   "source": [
    "# Data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61c323f3-ac14-4e12-922a-644680f56b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata():\n",
    "    \"\"\"\n",
    "    Extract metadata for the fuel emission datasets\n",
    "    \n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9e7840a-cb32-471a-ad23-256aab1d1d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def extract_raw_data(url, file_name):\n",
    "    \"\"\"\n",
    "    Extract raw data from a URL\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        URL to extract data from\n",
    "        \n",
    "    file_name : str or Path object\n",
    "        file name for raw data dump\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Request data from url\n",
    "        response = requests.get(url)\n",
    "        content_type = response.headers['content-type']\n",
    "        response_text = response.text\n",
    "        print(f'Response status: {response.status_code}\\nContent Type: {content_type}')\n",
    "\n",
    "        # Save request content to csv file\n",
    "        with open(file_name, mode='w', newline='') as csvfile:\n",
    "            csvfile.write(response_text)\n",
    "\n",
    "        print(f'csv file: {file_name} saved')\n",
    "        \n",
    "    # Catch errors    \n",
    "    except requests.exceptions.HTTPError as err_h:\n",
    "        print(f'HTTP error occured:{err_h}')\n",
    "    except requests.exceptions.ConnectionError as err_c:\n",
    "        print(f'Error connecting:{err_c}')\n",
    "    except requests.exceptions.Timeout as err_t:\n",
    "        print(f'Timeout Error:{err_t}')\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print(f'There was an unknown error:{err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39e4db12-45e6-4c38-a96e-edf9c90213ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_top_two_rows(input_file, output_file):\n",
    "    # Open the input CSV file for reading\n",
    "    with open(input_file, mode='r', newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        \n",
    "        # Read the first two rows from the input file\n",
    "        header_row = next(reader)\n",
    "        second_row = next(reader)\n",
    "        \n",
    "        # Merge the two rows into one header\n",
    "        merged_header = [f\"{header_row[i]} {second_row[i]}\" for i in range(len(header_row))]\n",
    "        \n",
    "        # Open the output CSV file for writing\n",
    "        with open(output_file, mode='w', newline='') as output_csvfile:\n",
    "            writer = csv.writer(output_csvfile)\n",
    "            \n",
    "            # Write the merged header to the output file\n",
    "            writer.writerow(merged_header)\n",
    "            \n",
    "            # Copy the rest of the rows from the input file to the output file\n",
    "            for row in reader:\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7e0a707-c502-4f24-a54a-9dfcb5ae41dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns():\n",
    "    \"\"\"\n",
    "    Rename dataframe columns so they are database friendly.\n",
    "\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4a35c8c-4458-4e76-9fd9-6bc9e70d8e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe():\n",
    "    \"\"\"\n",
    "    Clean the fuel consumption dataframe.\n",
    "\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7de96a-85e6-4440-b09e-7c577d67c3f0",
   "metadata": {},
   "source": [
    "## Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3300bb9c-743b-4fdd-aebe-64860a8221a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://natural-resources.canada.ca/sites/nrcan/files/oee/files/csv/MY2023%20Fuel%20Consumption%20Ratings.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61992468-9e90-486a-8e6f-fc3b4ab2c6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/jsh/vehicle-co2')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path.cwd()\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc9651b9-cd37-4b26-b8e0-253813a28cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare file names\n",
    "raw_path = path / 'data' / 'raw'\n",
    "raw_file_name = raw_path / 'fuel-ratings-raw.csv'\n",
    "merged_headers_file_name = raw_path / 'fuel-ratings-raw-headers-merged.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2aab196-1ad8-42b2-ba8d-6ce72fd28436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response status: 200\n",
      "Content Type: text/csv\n",
      "csv file: /home/jsh/vehicle-co2/data/raw/fuel-ratings-raw.csv saved\n"
     ]
    }
   ],
   "source": [
    "extract_raw_data(url, raw_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7df1846-415c-4bc9-989d-e4649b0e28f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_top_two_rows(raw_file_name, merged_headers_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7068d4ef-1ef3-4938-bbcc-198e4d522e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "unprocessed_fuel_ratings_df = pd.read_csv(merged_headers_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b23f5e8-a64b-4ef8-a425-3359165cef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "unprocessed_fuel_ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69537ba8-70b5-45f5-8c1c-cf08ef025ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_columns(unprocessed_fuel_ratings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fff1e3a-3a2d-4078-ae2b-ae2770c60df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_fuel_ratings_df = clean_dataframe(unprocessed_fuel_ratings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9a513ec2-40c1-4b07-bc79-206794390af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_first_table(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', newline='') as csvfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            rows = list(reader)\n",
    "\n",
    "        # Find index of first empty row\n",
    "        empty_row_idx = -1\n",
    "        for i, row in enumerate(rows):\n",
    "            if not any(row):\n",
    "                empty_row_idx = i\n",
    "                break\n",
    "                \n",
    "        if empty_row_idx >= 0:\n",
    "        # Create a new CSV file with only the rows before the first empty row\n",
    "            with open('test7.csv', 'w', newline='') as csvfile:\n",
    "                writer = csv.writer(csvfile)\n",
    "                writer.writerows(rows[:empty_row_idx])\n",
    "            print(f'Removed rows after the first empty row.')\n",
    "        else:\n",
    "            print(f'No empty row found in the file')\n",
    "    except FileNotFoundError:\n",
    "        print(f'File {file_path} not found.')\n",
    "    except Exception as e:\n",
    "        print('An error occured while processing the file:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "85d6d0d2-ba10-4594-9629-b5619d01124d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed rows after the first empty row.\n"
     ]
    }
   ],
   "source": [
    "# extract_first_table(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2e609a-4349-4a68-b476-a7f030fe60ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export notebook to module.\n",
    "from nbdev.export import nb_export\n",
    "path = Path.cwd()\n",
    "lib_path = path\n",
    "nb_path = path / 'datadownload.ipynb'\n",
    "nb_export(nb_path, lib_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
